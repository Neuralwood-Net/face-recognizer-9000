{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imgaug\n",
    "!pip install tensorflow-gpu\n",
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from mtcnn import MTCNN\n",
    "from tensorflow.image import crop_to_bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "# Connect to google cloud storage\n",
    "client = storage.Client()\n",
    "\n",
    "bucket_name = \"tdt4173-datasets\"\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "# Download videos from google cloud storage\n",
    "DATASET = \"faces/videos/faces_final.zip\"\n",
    "FILEPATH = \"/home/jupyter/data/faces/faces_final.zip\"\n",
    "blob = bucket.get_blob(DATASET)\n",
    "blob.download_to_filename(FILEPATH)\n",
    "!mkdir -p /home/jupyter/data/faces/videos/\n",
    "!unzip /home/jupyter/data/faces/faces_final.zip -d /home/jupyter/data/faces/videos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read input image\n",
    "vidcap = cv2.VideoCapture(\"/home/jupyter/data/faces/videos/Morgan/IMG_0039.MOV\")\n",
    "success, image = vidcap.read()\n",
    "\n",
    "# Convert to grayscale\n",
    "#gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "h,w, _ = gray.shape # 1080x1920 (rotated 90deg left)\n",
    "\n",
    "# Rotate\n",
    "#gray = np.reshape(gray, (h, w, 1))\n",
    "gray = np.array(np.rot90(gray, k=3))\n",
    "\n",
    "\n",
    "# Crop to square\n",
    "crop = iaa.CropToFixedSize(height=min([h, w]), width=min([h,w]), position='center')\n",
    "cropped = crop(image=gray)\n",
    "\n",
    "# Downsize\n",
    "img_size = 224\n",
    "resized = cv2.resize(cropped, (img_size, img_size))\n",
    "#resized = np.reshape(resized, (img_size, img_size, 1))\n",
    "print(resized.shape)\n",
    "\n",
    "ia.imshow(resized)\n",
    "\n",
    "images = [gray, cropped]\n",
    "#ia.imshow(ia.draw_grid(images, cols=len(images), rows=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = resized\n",
    "\n",
    "image = cv2.imread(\"/home/jupyter/data/faces/images/sampling_crop/Morgan/morgan_2213.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-5, 5)),\n",
    "    iaa.CropAndPad(percent=(-0.05, 0.1), pad_mode=ia.ALL, pad_cval=(0, 0)), # crop images by -5% to 10% of their height/width\n",
    "    iaa.AdditiveGaussianNoise(scale=(0, 20)), \n",
    "    iaa.GaussianBlur(sigma=(0, 1.0)), # Blur images using a gaussian kernel with sigma between 0.0 and 1.0.\n",
    "    iaa.Add((-10,10)), # change brightness of images (by -10 to 10 of original value)\n",
    "    iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, cval=(0,0)) # translate by -10 to +10 percent (per axis)\n",
    "], random_order=True)\n",
    "\n",
    "\n",
    "images_aug = [seq(image=image) for _ in range(16)] # random order is sampled once per batch, and not once per image in the batch\n",
    "rows=2\n",
    "print(\"Augmented:\")\n",
    "\n",
    "ia.imshow(ia.draw_grid(images_aug, cols=len(images_aug)/rows, rows=rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.image import crop_to_bounding_box\n",
    "def crop_by_bounding_box(img, detector, vertical_expand=0.05, draw=False):\n",
    "    result = detector.detect_faces(img)\n",
    "    if len(result) == 0:\n",
    "        return None\n",
    "    bounding_box = result[0]['box']\n",
    "    \n",
    "    if draw:\n",
    "        before = img.copy()\n",
    "        cv2.rectangle(img,\n",
    "                  (bounding_box[0], bounding_box[1]),\n",
    "                  (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n",
    "                  (255,255,255),\n",
    "                  10)\n",
    "\n",
    "    y = bounding_box[1]\n",
    "    x = bounding_box[0]\n",
    "    height = bounding_box[3]\n",
    "    width = bounding_box[2]\n",
    "\n",
    "    # Account for top left corner outside image\n",
    "    if y < 0:\n",
    "        height += y\n",
    "        y = 0\n",
    "    if x < 0:\n",
    "        width += x\n",
    "        x = 0\n",
    "\n",
    "    # Expand bounding box vertically by vertical_expand % in each direction\n",
    "    # Move y-coord of top-left corner upwards\n",
    "    old_y = y\n",
    "    y = max(y - int(vertical_expand * height), 0)\n",
    "    height += (old_y - y)\n",
    "\n",
    "    # Increase height of bounding box\n",
    "    h, w, _ = img.shape\n",
    "    height = min(int((1 + vertical_expand) * height), h)\n",
    "\n",
    "    # Fill horizontally or vertically until width = height\n",
    "    if height > width:\n",
    "        if height > w:\n",
    "            x = 0\n",
    "            width = w\n",
    "        else:\n",
    "            diff_to_fill = height - width\n",
    "\n",
    "            # Fill leftwards\n",
    "            old_x = x\n",
    "            x = max(0, x - int(diff_to_fill / 2))\n",
    "            x_change = (old_x - x)\n",
    "            diff_to_fill -= x_change\n",
    "            width += x_change\n",
    "\n",
    "            # Fill rightwards\n",
    "            width = min(width + diff_to_fill, w - x)\n",
    "    else:\n",
    "        diff_to_fill = width - height\n",
    "        # Fill upwards\n",
    "        old_y = y\n",
    "        y = max(0, y - int(diff_to_fill/2))\n",
    "        y_change = (old_y - y)\n",
    "        diff_to_fill -= y_change\n",
    "        height += y_change\n",
    "\n",
    "        # Fill downwards\n",
    "        height += min(height + diff_to_fill, h - y)\n",
    "    # Cut height if larger than width\n",
    "    if height > w:\n",
    "        diff = height - w\n",
    "        y += int(diff/2)\n",
    "        height -= diff\n",
    "\n",
    "    crop = crop_to_bounding_box(img, y, x, height, width).numpy()\n",
    "\n",
    "    if draw: \n",
    "        images = [before, img, crop]\n",
    "        plt.imshow(ia.draw_grid(images, cols=len(images), rows=1))\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture(\"/home/jupyter/data/faces/videos/Lars/IMG_0004.MOV\")\n",
    "frame = 0\n",
    "vidcap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "success, img = vidcap.read()\n",
    "\n",
    "img = np.rot90(img, k=3)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "res = crop_by_bounding_box(img, detector, vertical_expand=0.1, draw=False)\n",
    "print(res.shape)\n",
    "resized = cv2.resize(res, (128, 128)) / 255.0\n",
    "plt.imshow(resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "morgan_lars_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1CPygmiQuN4yUeDB-gNkGtNCIiED-Ydua",
      "authorship_tag": "ABX9TyOaM3AvLufqt4s/Fia71s0z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neuralwood-Net/face-recognizer-9000/blob/main/notebooks/morgan_lars_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH6k1V5shoVg"
      },
      "source": [
        "# Morgan and Lars Neural Net Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqcCktR3hrNG"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rnSlQJGV9xh"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.cloud import storage"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4gqZD7ulPLt",
        "outputId": "706a837e-5889-4dfe-ccbb-d7ccdc7188b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6gXbbcThtax"
      },
      "source": [
        "### Read and prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH1XN6kdXAdd"
      },
      "source": [
        "client = storage.Client.from_service_account_json(\"/content/drive/My Drive/## Project/TDT4173 Deep Learning Project-91d3b469375c.json\")\n",
        "\n",
        "bucket_name = \"tdt4173-datasets\"\n",
        "bucket = client.get_bucket(bucket_name)\n",
        "\n",
        "blob_name = \"celeba/tensors/celebalign_processed_64_100000_horizontal.torch\"\n",
        "blob = bucket.get_blob(blob_name)\n",
        "data_file = \"/content/celebalign_processed_64_100000_horizontal.torch\"\n",
        "blob.download_to_filename(data_file)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS9Hr-4FXDAg"
      },
      "source": [
        "data = torch.load(data_file)\n",
        "\n",
        "NUM_CLASSES = data[\"num_classes\"]\n",
        "\n",
        "(\n",
        "    X_train,\n",
        "    X_val_test,\n",
        "    y_train,\n",
        "    y_val_test\n",
        " ) = train_test_split(data[\"x\"], data[\"y\"], test_size=0.30)\n",
        "\n",
        "(\n",
        "    X_val,\n",
        "    X_test,\n",
        "    y_val,\n",
        "    y_test\n",
        " ) = train_test_split(X_val_test, y_val_test, test_size=0.50)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfMHbGt5YbQa",
        "outputId": "6c5245eb-7dd8-49d5-a5b7-0b588b170a2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train.shape, y_val.shape, y_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([70009]), torch.Size([15002]), torch.Size([15003]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhmFsxblhxE6"
      },
      "source": [
        "### Prepare the data as datasets in loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ohCb2cwYjzx"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "X_train = X_train.view(-1, 1, 64, 64).float()\n",
        "X_val = X_val.view(-1, 1, 64, 64).float()\n",
        "X_test = X_test.view(-1, 1, 64, 64).float()\n",
        "\n",
        "# Wrap the tensors in a wrapper\n",
        "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "val = torch.utils.data.TensorDataset(X_val, y_val)\n",
        "test = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "\n",
        "# Create the dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUVzf0lAul5y"
      },
      "source": [
        "### Create functions for training, validation, and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPShj33zpVvq"
      },
      "source": [
        "def validate(model, val_loader, loss_func):\n",
        "    correct = 0\n",
        "    for batch_idx, (X_batch, y_batch) in enumerate(val_loader):\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        output = model(X_batch.float())\n",
        "        loss = loss_func(output, y_batch)\n",
        "\n",
        "        predicted = torch.argmax(output, 1)\n",
        "        correct += (predicted == y_batch).sum()\n",
        "\n",
        "    acc = float(correct*100) / float(BATCH_SIZE*(batch_idx+1))\n",
        "\n",
        "    return loss, acc"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANlynXw7alW-"
      },
      "source": [
        "def fit(model, train_loader, val_loader):\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    EPOCHS = 10\n",
        "    EVAL_EVERY = 50\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(6, EPOCHS + 1):\n",
        "        correct = 0\n",
        "        it = tqdm(train_loader, desc=f\"Epoch: {epoch}\")\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(it):\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch.float())\n",
        "            loss = loss_function(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            predicted = torch.argmax(output, 1)\n",
        "            correct += (predicted == y_batch).sum()\n",
        "\n",
        "            if batch_idx % EVAL_EVERY == 0:\n",
        "                acc = float(correct*100) / float(BATCH_SIZE*(batch_idx+1))\n",
        "\n",
        "                val_loss, val_acc = validate(model, val_loader, loss_function)\n",
        "\n",
        "\n",
        "                it.set_postfix({\n",
        "                    \"Loss\": f\"{loss.item():.4f}\",\n",
        "                    \"Acc\": f\"{acc:.2f}\",\n",
        "                    \"Val loss\": f\"{val_loss.item():.4f}\",\n",
        "                    \"Val acc\": f\"{val_acc:.2f}\",\n",
        "                })"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V22RhiLQdkA5"
      },
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "\n",
        "    for test_imgs, test_labels in test_loader:\n",
        "        test_imgs, test_labels = test_imgs.to(device), test_labels.to(device)\n",
        "        output = model(test_imgs.float())\n",
        "        predicted = torch.argmax(output, dim=1)\n",
        "        correct += (predicted == test_labels).sum()\n",
        "\n",
        "    print(f\"Test accuracy: {float(correct) / (len(test_loader)*BATCH_SIZE):.3f}%\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWDUGOMqh2jh"
      },
      "source": [
        "### Prepare and train the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2JPv3bfhm4_"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    size_after_conv = 16 * 16 * 64\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.features = nn.Sequential(   \n",
        "            nn.Conv2d(1, 32, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(),\n",
        "            nn.Conv2d(32, 32, kernel_size=5, padding=2),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "        )\n",
        "        self.classify = nn.Sequential(\n",
        "            nn.Linear(self.size_after_conv, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, NUM_CLASSES),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(-1, self.size_after_conv)\n",
        "        x = self.classify(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi6LA7V5kV8-",
        "outputId": "84bb017d-57f7-412b-8973-f0b13ad54feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cnn = CNN().to(device)\n",
        "print(cnn)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): ReLU()\n",
            "    (9): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (classify): Sequential(\n",
            "    (0): Linear(in_features=16384, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=3408, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMDBVBzFkX9U",
        "outputId": "5f3e21c5-973f-4124-9b92-d98ad9f7e8b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fit(cnn, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1: 100%|██████████| 2188/2188 [01:49<00:00, 20.00it/s, Loss=8.1625, Acc=0.02, Val loss=8.1270, Val acc=0.01]\n",
            "Epoch: 2: 100%|██████████| 2188/2188 [01:48<00:00, 20.09it/s, Loss=8.1624, Acc=0.03, Val loss=8.1388, Val acc=0.01]\n",
            "Epoch: 3: 100%|██████████| 2188/2188 [01:48<00:00, 20.11it/s, Loss=8.1627, Acc=0.04, Val loss=8.1486, Val acc=0.01]\n",
            "Epoch: 4: 100%|██████████| 2188/2188 [01:48<00:00, 20.10it/s, Loss=8.1631, Acc=0.04, Val loss=8.1568, Val acc=0.01]\n",
            "Epoch: 5:   2%|▏         | 49/2188 [00:04<08:02,  4.44it/s, Loss=8.1178, Acc=0.06, Val loss=8.1512, Val acc=0.01]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-_AenTmlHIg"
      },
      "source": [
        "evaluate(cnn, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6wJlK79Gp2k"
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knfsRG3emouC"
      },
      "source": [
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "for idx, (image, label) in enumerate(zip(images, labels)):\n",
        "    pred = int(torch.argmax(cnn(image.view(-1, 1, 64, 64).to(device))))\n",
        "    convert = {0: \"Lars\", 1: \"Morgan\", 2: \"Kjartan\", 3: \"Ingen\"}\n",
        "    \n",
        "    plt.imshow(image.view(64, 64).cpu(), cmap=\"gray\")\n",
        "    plt.text(2, 54, f\"Image {idx + 1}\", fontsize=14, color=\"white\")\n",
        "    plt.text(2, 58, f\"Predicted: `{convert[pred]}`\", fontsize=14, color=\"white\")\n",
        "    plt.text(2, 62, f\"Actual   : `{convert[label.item()]}`\", fontsize=14, color=\"white\")\n",
        "    plt.pause(0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6x34CiPQT6y"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaYcByaqGjXw"
      },
      "source": [
        "cnn.eval()\n",
        "\n",
        "class Label:\n",
        "    def __init__(self, label):\n",
        "        self.label = label\n",
        "    \n",
        "    def item(self):\n",
        "        return self.label\n",
        "\n",
        "\n",
        "filename = \"/content/lars_5.png\"\n",
        "image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "image = cv2.resize(image, (64, 64)) / 255.0\n",
        "plt.imshow(image, cmap=\"gray\")\n",
        "convert = {0: \"Lars\", 1: \"Morgan\", 2: \"Kjartan\", 3: \"Ingen\"}\n",
        "\n",
        "pred = int(torch.argmax(cnn(torch.Tensor(image).view(-1, 1, 64, 64).to(device))))\n",
        "# plt.text(2, 58, f\"Predicted: `{convert[pred]}`\", fontsize=14, color=\"white\")\n",
        "# plt.text(2, 62, f\"Actual   : `{convert[label.item()]}`\", fontsize=14, color=\"white\")\n",
        "\n",
        "if \"morgan\" in filename:\n",
        "    label = Label(1)\n",
        "elif \"lars\" in filename:\n",
        "    label = Label(0)\n",
        "else:\n",
        "    label = Label(3)\n",
        "\n",
        "print(f\"Predicted: `{convert[pred]}`\" )\n",
        "print(f\"Actual   : `{convert[label.item()]}`\")\n",
        "\n",
        "# plt.imshow(image.view(64, 64).cpu().to_numpy(), cmap=\"gray\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N91hUPwQQxQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
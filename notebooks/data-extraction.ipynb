{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats-vs-dogs/\n",
      "cats-vs-dogs/processed/catsvsdogs.npy\n",
      "cats-vs-dogs/raw-data/\n",
      "cats-vs-dogs/raw-data/catsanddogs.zip\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "\n",
    "bucket_name = \"tdt4173-datasets\"\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "blobs = bucket.list_blobs()\n",
    "for blob in blobs:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"faces/videos/faces.zip\"\n",
    "blob = bucket.get_blob(DATASET)\n",
    "blob.download_to_filename(\"data/faces.zip\")\n",
    "\n",
    "# faces.zip should have the following structure: class/video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir data/faces\n",
    "!unzip data/faces.zip data/faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Just resize image and keep aspect ratio\n",
    "def preprocess_image(img, img_size=128):\n",
    "    # Convert to grayscale\n",
    "    # Note: we convert from BGR as VideoCapture \n",
    "    # converts the images to BGR color frame by defualt\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Make image square by filling with black padding\n",
    "    h, w = img.shape\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img,\n",
    "        top=0,\n",
    "        right=max(0, h-w),\n",
    "        bottom=max(0, w-h),\n",
    "        left=0,\n",
    "        borderType=0,\n",
    "    )\n",
    "\n",
    "    # Resize image to specified size\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_label(name, folder):\n",
    "    # Find maximum label of files named as \"name_##.jpg\" in directory\n",
    "    highest = 0\n",
    "    for file in os.listdir(folder):\n",
    "        if name not in file:\n",
    "            continue\n",
    "        label = file.rpartition(os.sep)[2].split(\".\")[0].rpartition(\"_\")[2]\n",
    "        highest = max(highest, int(label))\n",
    "    return highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_video(video, target_dir=None, file_prefix=None, img_size=128, processing_func=preprocess_images, silent=False):    \n",
    "    \"\"\"\n",
    "    Saves every single frame of a video as images.\n",
    "    Converts to greyscale, pads with black to make square images and resizes.\n",
    "    \"\"\"\n",
    "    \n",
    "    vidcap = cv2.VideoCapture(video)\n",
    "    \n",
    "    video_name = video.rpartition(os.sep)[2].split(\".\")[0]\n",
    "    \n",
    "    # Where to save images\n",
    "    if not target_dir:\n",
    "        target_dir = os.getcwd() + f\"/images_from_video_{video_name}\"\n",
    "        os.makedirs(target_dir, exist_ok=True) \n",
    "\n",
    "    # Use video file name as prefix if not specified\n",
    "    if not file_prefix:\n",
    "        file_prefix = video_name\n",
    "\n",
    "    label = max_label(file_prefix, target_dir)\n",
    "    count = 0\n",
    "    \n",
    "    while True:\n",
    "        # Read image from video\n",
    "        success, image = vidcap.read()\n",
    "        \n",
    "        # if frame is read correctly, succes is True\n",
    "        if not success:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            return count\n",
    "        \n",
    "        # Convert to greyscale, make square and resize\n",
    "        image = processing_func(image, img_size)\n",
    "\n",
    "        # Save to file\n",
    "        label += 1\n",
    "        count += 1\n",
    "        file_name = f\"{file_prefix}_{str(count)}.jpg\"\n",
    "        path = os.path.join(target_dir, file_name)\n",
    "        cv2.imwrite(path, image)\n",
    "\n",
    "        # Check that image is not corrupted\n",
    "        if cv2.imread(path) is None:\n",
    "            print(f\"WARNING: image corrupted at path {path}\")\n",
    "            os.remove(path)\n",
    "        else:\n",
    "            if not silent:\n",
    "                print(f'Image successfully written at {path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KJARTAN = \"data/faces/Kjartan\"\n",
    "LARS = \"data/faces/Lars\"\n",
    "MORGAN = \"data/faces/Morgan\"\n",
    "OTHER = \"data/faces/Other\"\n",
    "\n",
    "LABELS = {KJARTAN: 0, LARS: 1, MORGAN: 2, OTHER: 3}\n",
    "counts = {KJARTAN: 0, LARS: 0, MORGAN: 0, OTHER: 0}\n",
    "\n",
    "\n",
    "# For each class, extract all frames from all videos, preprocess image and save to data/faces/label\n",
    "for label in LABELS:\n",
    "    count = 0\n",
    "    for video in tqdm(os.listdir(label)):\n",
    "        # Extract each frame of video, preprocess and save to directory\n",
    "        target_dir = f\"data/faces/images/{label.rpartition(\"/\")[2]}\"\n",
    "        count += extract_images_from_video(video, target_dir, processing_func=preprocess_image)\n",
    "    counts[label] = count\n",
    "    \n",
    "\n",
    "print(f\"Kjartan: {counts[KJARTAN]}, Lars: {counts[LARS]}, Morgan: {counts[MORGAN]}, Other: {counts[Other]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save images to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r data/faces/images.zip data/faces/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_directory = \"faces/images/images.zip\"\n",
    "blob = bucket.blob(cloud_directory)\n",
    "\n",
    "source_file_name = \"data/faces/images.zip\"\n",
    "blob.upload_from_filename(source_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes for data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Currently every single frame of the video is used, so each frame needs to contain the face of the person\n",
    "- All videos should use the same camera settings (resolution etc)\n",
    "- Should film with as low resolution as possible\n",
    "- Low framerate is probably ideal\n",
    "- When saving videos, store them as `folder/Class/video.mp4` and zip `folder`"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
